###"Radio Lab Right to be forgotten"###

I think public data should be stored, and the use of the Internet and online tools is unblameable. So the pattern that is used in the past – everything existed in the newspaper, people read the news, forgot it, the newspapers were stored in a library as well as the public data they carried with, and the information did not disappear but only vanished from the public memory. My idea is similar to what the Europe has done. That is, to narrow the access to the certain information, as long as the person applies for, and his/her application is approved. For instance, a database can be created to specially store this kind of information to be forgotten. When the information is needed in a certain situation, for example when the person is applying for higher education or a job, the relevant institutions have the right to enter that database.

There are, undoubtedly, several difficulties of this task: to what extent can the person be forgiven? Is it fair enough for the victims like the ladies in Seth’s case? And another difficulty that keeps coming into my mind when listening to this podcast is the moral hazard that the institutions like Cleverland.com faced. The word moral hazard is originally used in the insurance industry. In the case of Cleverland.com, as long as the information is deleted, it will be Cleverland.com’s responsibility to take whatever consequence it might bring up, instead of the person. The risk so high for the website to help a person.

This reminds me off the movie Sheep Without a Shepherd, in which the daughter and mother accidentally killed the son of the police chief, and the father used relevant skills he learned from all kinds of movies to conceal the truth and cheated everyone. It is hard to tell whether the father is right or wrong: the family killed a person in real, but it is due to a legitimate defense as the person is going to hurt the daughter.

###"The Daily The End of Privacy as we know it?"###
From my viewpoint a system like ClearView has more risks than benefits. Undoubtedly it can bring a better environment to the government institutions and the police departments, but does that mean it can offer a better and safer society? More crimes in other fields might start to exist in terms of privacy, which might not be covered by speeding up the efficiency of the police. Yes, it might work as a similar logic can be found on laws related to the gun using, but it requires a high moral standard of the whole society, which is not controllable and credible. Even the founder and the company promised not to leak any information to the public, no one can ensure that everyone in this company will not make any mistake; profit making is tempting, and the company seems to be indifferent to it and care much about privacy (even the information of the company itself and the founder were both protected properly), but a question mark is needed for the future situation. The only way I can think of to constrict ClearView is by law, but I am not sure whether this can work. Based on the podcast, ClearView seems to gain more power than the police, as is shown that the journalist asked the police officer to find her information. To this certain extent, it looks like the more private information one can get, the more confident and powerful they can be, which is horrifying.
